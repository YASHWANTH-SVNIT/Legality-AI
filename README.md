# Legality AI - AI-Powered Contract Risk Analyzer

An intelligent contract analysis system that uses adversarial AI agents and RAG (Retrieval-Augmented Generation) to identify risky clauses in legal contracts and suggest safer alternatives.

--------------------------------------------

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
- [How to Run](#how-to-run)
- [How It Works](#how-it-works)
- [Contributors](#contributors)

---

## ğŸ¯ Overview

Legality AI analyzes legal contracts using a sophisticated pipeline powered by multiple AI agents. The system identifies risky clauses, evaluates them through adversarial analysis, and generates safer alternatives while detecting compound risks across the entire contract.

**Built as a portfolio project to demonstrate:**
- Advanced RAG implementation with semantic search
- Multi-agent AI systems with adversarial analysis
- Full-stack development with modern frameworks
- Production-grade error handling and fallback mechanisms

---

## âœ¨ Key Features

### Core Capabilities
- **ğŸ“„ PDF Contract Analysis** - Upload and process legal contracts in PDF format
- **ğŸ¤– Adversarial AI Agents** - 3-agent system (Pessimist, Optimist, Arbiter) for balanced risk assessment
- **ğŸ” RAG-Powered Detection** - Semantic search against 640+ verified legal clauses
- **âœï¸ AI-Generated Fixes** - Automatically suggests safer alternative clauses
- **âš ï¸ Compound Risk Detection** - Identifies interactions between multiple risky clauses
- **ğŸ“Š Interactive Dashboard** - Visual risk summary with expandable clause details
- **ğŸ’¬ User Feedback System** - Collect feedback to improve analysis accuracy
- **ğŸ”„ Multi-Model Fallback** - Automatic switching between AI models if one fails

---

## ğŸ›  Tech Stack

### Backend
- **Python 3.11** - Core programming language
- **FastAPI** - High-performance async REST API framework
- **ChromaDB** - Vector database for semantic search
- **Sentence Transformers** - Embedding generation (all-MiniLM-L6-v2)
- **OpenRouter API** - Multi-model LLM access (Claude, GPT-4, etc.)
- **PyPDF2** - PDF text extraction
- **Pydantic** - Data validation and settings management
- **Uvicorn** - ASGI server

### Frontend
- **React 18.2** - UI framework
- **TypeScript** - Type-safe JavaScript
- **Tailwind CSS** - Utility-first styling
- **Axios** - HTTP client
- **React Router** - Client-side routing

### AI/ML Components
- **LangChain** - LLM orchestration framework
- **Langfuse** - LLM observability (optional)
- **OpenAI SDK** - Unified API client for multiple LLM providers

### Development Tools
- **Git** - Version control
- **npm** - Frontend package management
- **pip** - Python package management
- **VS Code** - Development environment

## ğŸ“ Project Structure
```
legality_ai/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                    # FastAPI routes and main app
|   |   |   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ requests.py     
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ responses.py                   
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py     # Contract upload & analysis endpoints
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ feedback.py     # User feedback endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.py       # Health check endpoint
â”‚   â”‚   â”‚   â””â”€â”€ main.py             # FastAPI application entry
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                   # Core models and utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py           # Pydantic data models
â”‚   â”‚   â”‚   â””â”€â”€ llm_client.py       # Multi-model LLM client with fallback
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ config/                 # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ settings.py         # App settings and thresholds
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rag/                    # RAG components
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py     # ChromaDB interface
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚   â”‚   â”‚   â””â”€â”€ category_detector.py # Stage 2: Category detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ document_processor/ # Stage 1: PDF processing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metadata_extractor.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ definition_extractor.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ semantic_chunker.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_analyzer/      # Stage 3: Adversarial analysis
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pessimist_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ optimist_agent.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ arbiter_agent.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adversarial_analyzer.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ fix_generator/      # Stage 4: Fix generation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ fix_generator.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ compound_detector/  # Stage 5: Compound risks
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ compound_detector.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ feedback_manager/   # Stage 6: Feedback
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ feedback_manager.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ learning_loop.py
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ analyzer.py         # Main orchestrator
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/                  # Utilities
â”‚   â”‚       â””â”€â”€ text_utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ build_pipeline/             # Vector DB construction
â”‚   â”‚   â””â”€â”€ build_vector_db.py      # Build ChromaDB from CUAD dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                       # Training data
â”‚   â”‚   â”œâ”€â”€ verified_golden_rules.json    # 533 safe clauses
â”‚   â”‚   â””â”€â”€ extracted_clauses.json        # 107 risky clauses
â”‚   â”‚
â”‚   â”œâ”€â”€ chroma_db_gold/             # Vector database (generated)
â”‚   â”œâ”€â”€ uploads/                    # Temporary PDF storage
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                        # Environment variables
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â””â”€â”€ run.py                      # Application entry point
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/             # File upload component
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FileUploader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ viewer/             # Results display
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ClauseCard.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ CompactClauseCard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ risk/               # Risk visualization
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RiskBadge.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ RiskSummary.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ feedback/           # User feedback
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FeedbackButtons.tsx
â”‚   â”‚   â”‚   â””â”€â”€ common/             # Shared components
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.tsx        # Landing page with upload
â”‚   â”‚   â”‚   â””â”€â”€ AnalysisPage.tsx    # Results page
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts              # API client
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useAnalysis.ts      # Analysis polling hook
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts            # TypeScript interfaces
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ colors.ts           # Risk color utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ App.tsx                 # Main app component
â”‚   â”‚   â”œâ”€â”€ index.tsx               # React entry point
â”‚   â”‚   â””â”€â”€ index.css               # Global styles
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                        # Frontend environment variables
â”‚   â”œâ”€â”€ package.json                # Node dependencies
â”‚   â”œâ”€â”€ tailwind.config.js          # Tailwind configuration
â”‚   â””â”€â”€ tsconfig.json               # TypeScript configuration
â”‚
â””â”€â”€ README.md                       # This file
```

---

## ğŸš€ Installation & Setup

### Prerequisites

- **Python 3.11+**
- **Node.js 18+** & npm
- **OpenRouter API Key** 
- **Git**

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/legality_ai.git
cd legality_ai
```

### Step 2: Backend Setup
```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env
```

**Edit `backend/.env`:**
```env
# Required
OPENROUTER_API_KEY=your_key_here

# Optional
LANGFUSE_ENABLED=false
ENVIRONMENT=development
LOG_LEVEL=INFO
```

### Step 3: Build Vector Database
```bash
# Build ChromaDB from CUAD dataset (one-time setup)
python build_pipeline/build_vector_db.py
```

**Expected output:**
```
ğŸ—ƒï¸  INITIALIZING GOLDEN STANDARD DATABASE...
    Loaded 533 safe clauses.
    Loaded 107 risky clauses.
    Indexing 640 total documents...
âœ… SUCCESS! Vector DB created
```

### Step 4: Frontend Setup
```bash
# Navigate to frontend
cd ../frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env
```

**Edit `frontend/.env`:**
```env
REACT_APP_API_URL=http://localhost:8000
REACT_APP_ENV=development
```

---

## â–¶ï¸ How to Run

### Start Backend Server
```bash
cd backend
python run.py
```

**Backend will start at:** http://localhost:8000
- API Documentation: http://localhost:8000/docs

### Start Frontend Server
```bash
cd frontend
npm start
```

**Frontend will start at:** http://localhost:3000

### Test the System

1. Open http://localhost:3000
2. Upload a contract PDF (sample provided in `backend/data/sample_nda.pdf`)
3. Wait 30-60 seconds for analysis
4. View results with risk scores and suggested fixes

---

## ğŸ”„ How It Works

### Stage 1: Document Processing
1. **PDF Extraction** - Extracts text from uploaded PDF
2. **Metadata Extraction** - Identifies contract type, parties, dates
3. **Definition Extraction** - Finds defined terms (e.g., "Confidential Information")
4. **Semantic Chunking** - Splits document into coherent chunks using embeddings

### Stage 2: RAG-Powered Category Detection
1. Queries vector database with each chunk
2. Matches against category prototypes (e.g., "Termination", "Liability")
3. Applies 3-zone filtering:
   - **Zone 1 (Noise):** < 30% similarity - ignore
   - **Zone 2 (Courtroom):** 30-85% similarity - needs AI review
   - **Zone 3 (Safe Check):** > 85% similarity - verify against safe standards
4. Retrieves relevant examples for context

### Stage 3: Adversarial Risk Analysis
Each risky clause is analyzed by 3 AI agents:

1. **Pessimist (Red Team):**
   - Assumes worst-case interpretation
   - Scores risk 0-100 (biased high)
   - Identifies hidden dangers

2. **Optimist (Blue Team):**
   - Finds legitimate business justifications
   - Scores defensibility 0-100
   - Identifies mitigating factors

3. **Arbiter (Judge):**
   - Reviews both arguments
   - Makes final balanced verdict
   - Assigns final risk score and level

### Stage 4: Fix Generation
- AI generates safer alternative clauses
- Maintains legal validity
- Balances both parties' interests
- Provides explanation of changes

### Stage 5: Compound Risk Detection
- Detects patterns across multiple clauses
- Examples:
  - Termination + Unlimited Liability
  - Non-Compete + Broad IP Assignment
  - Unilateral Changes + No Notice Period
- Validates patterns with LLM
- Suggests holistic mitigations

### Stage 6: User Feedback Collection
- False positive reporting
- False negative reporting
- Fix approval/rejection
- Stores feedback for future model improvement

## ğŸ›  Known Limitations

- This system does not replace legal professionals
- Only English-language contracts are currently supported
- Risk scores are probabilistic and AI-generated
- This is a prototype-grade system intended for research and evaluation


## ğŸ‘¨â€ğŸ’» Contributors

**Yashwanth N** 
      &
**Divya Yadav**

## ğŸ™ Acknowledgments

- **CUAD Dataset** - Contract Understanding Atticus Dataset for training data
- **OpenRouter** - Unified API access to multiple LLM providers
- **ChromaDB** - Open-source vector database
- **Sentence Transformers** - Pre-trained embedding models
- **FastAPI** - Modern Python web framework

---

**Built with â¤ï¸ as a portfolio project showcasing AI/ML engineering and full-stack development skills**